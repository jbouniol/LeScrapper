{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    return links\n",
    " \n",
    "def get_all_links():\n",
    "    links = []\n",
    "    for n in range(1,80):\n",
    "        h = get_link('https://stackoverflow.com/questions/tagged/web-scraping?tab=frequent&page=' + str(n) + '&pagesize=50')\n",
    "        links.append(h)\n",
    "    return links\n",
    "\n",
    "links = get_all_links()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendre les urls de la forme https://stackoverflow.com/questions/un_nombre\n",
    "def get_urls(urls):\n",
    "    url = []\n",
    "    for url_list in urls:\n",
    "        for i in url_list:\n",
    "            if i is not None:\n",
    "                if i.startswith('/questions/'):\n",
    "                    for n in range(0,10):\n",
    "                        if i.startswith('/questions/'+str(n)):\n",
    "                            url.append('https://stackoverflow.com'+i)\n",
    "    return url\n",
    "\n",
    "urls = get_urls(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_series = pd.Series(urls)\n",
    "unique_urls = urls_series.unique()\n",
    "len(unique_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am working with selenium to scrape some data...</td>\n",
       "      <td>Once you wait for the element and moving forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm trying to develop a simple web scraper. I ...</td>\n",
       "      <td>EDIT Sept 2021: phantomjs isn't maintained any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am trying to import data from the following ...</td>\n",
       "      <td>Tl;Dr\\nAdapted from my answer to How to know i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What’s the difference between getting text and...</td>\n",
       "      <td>To start with, text is a property where as inn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Closed. This question needs details or clarity...</td>\n",
       "      <td>Here's a short snippet using the SoupStrainer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm trying to pass a variable into a page.eval...</td>\n",
       "      <td>You have to pass the variable as an argument t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm having trouble parsing HTML elements with ...</td>\n",
       "      <td>You can refine your search to only find those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I do a lot of HTML parsing in my line of work....</td>\n",
       "      <td>jsoup\\nSelf plug: I have just released a new J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm trying to scrape product information from ...</td>\n",
       "      <td>It really depends on how do you need to scrape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Basically, I want to use BeautifulSoup to grab...</td>\n",
       "      <td>Try this:\\nfrom bs4 import BeautifulSoup from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  I am working with selenium to scrape some data...   \n",
       "1  I'm trying to develop a simple web scraper. I ...   \n",
       "2  I am trying to import data from the following ...   \n",
       "3  What’s the difference between getting text and...   \n",
       "4  Closed. This question needs details or clarity...   \n",
       "5  I'm trying to pass a variable into a page.eval...   \n",
       "6  I'm having trouble parsing HTML elements with ...   \n",
       "7  I do a lot of HTML parsing in my line of work....   \n",
       "8  I'm trying to scrape product information from ...   \n",
       "9  Basically, I want to use BeautifulSoup to grab...   \n",
       "\n",
       "                                              answer  \n",
       "0  Once you wait for the element and moving forwa...  \n",
       "1  EDIT Sept 2021: phantomjs isn't maintained any...  \n",
       "2  Tl;Dr\\nAdapted from my answer to How to know i...  \n",
       "3  To start with, text is a property where as inn...  \n",
       "4  Here's a short snippet using the SoupStrainer ...  \n",
       "5  You have to pass the variable as an argument t...  \n",
       "6  You can refine your search to only find those ...  \n",
       "7  jsoup\\nSelf plug: I have just released a new J...  \n",
       "8  It really depends on how do you need to scrape...  \n",
       "9  Try this:\\nfrom bs4 import BeautifulSoup from ...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "import random\n",
    "session = HTMLSession()\n",
    "data = []\n",
    "executor = ThreadPoolExecutor(max_workers=11)\n",
    "\n",
    "def scrape_url(urls2) :\n",
    "    for url in urls2:\n",
    "        r = session.get(url)\n",
    "        question_div = r.html.find('div.s-prose.js-post-body', first=True)\n",
    "        question = question_div.text if question_div else \"\"\n",
    "        answer_div = r.html.find('div.answercell.post-layout--right', first=True)\n",
    "        answer = answer_div.text if answer_div else \"\"\n",
    "        data.append({\"question\": question, \"answer\": answer})\n",
    "        time.sleep(np.random.uniform(0.02,0.05))\n",
    "    return data\n",
    "future = executor.submit(scrape_url, urls)\n",
    "data = future.result()\n",
    "dftest = pd.DataFrame(data)\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stackoverflow1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    return links\n",
    " \n",
    "def get_all_links():\n",
    "    links = []\n",
    "    for n in range(1,1020):\n",
    "        h = get_link('https://stackoverflow.com/questions/tagged/web-scraping?tab=active&page='+ str(n) +'&pagesize=50')\n",
    "        links.append(h)\n",
    "    return links\n",
    "\n",
    "links1 = get_all_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85669"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls1 = get_urls(links1)\n",
    "urls1, len(urls1)\n",
    "#retier les doublons\n",
    "urls_series1 = pd.Series(urls1)\n",
    "unique_urls1 = urls_series1.unique()\n",
    "len(unique_urls1)\n",
    "urls1 = unique_urls1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls1 = unique_urls1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(urls2) :\n",
    "    for url in urls2:\n",
    "        r = session.get(url)\n",
    "        question_div = r.html.find('div.s-prose.js-post-body', first=True)\n",
    "        question = question_div.text if question_div else \"\"\n",
    "        answer_div = r.html.find('div.answercell.post-layout--right', first=True)\n",
    "        answer = answer_div.text if answer_div else \"\"\n",
    "        data.append({\"question\": question, \"answer\": answer})\n",
    "        time.sleep(np.random.uniform(0.02,0.5))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "data = []\n",
    "executor = ThreadPoolExecutor(max_workers=11)\n",
    "future1 = executor.submit(scrape_url, urls1)\n",
    "data1 = future1.result()\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import time from playwright.sync_api import sy...</td>\n",
       "      <td>Locators check visibility, but you don't care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am trying to scroll the datasheet automatica...</td>\n",
       "      <td>Try this:\\ndocument.querySelector(\".showMoreRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I tried to web scraping from this website to g...</td>\n",
       "      <td>Replace\\nsales = cells[4].text.strip()\\nWith\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I would like to extract data from the the tabl...</td>\n",
       "      <td>Instead of using SelectorGadget or element ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm creating a scraper connected to a Telegram...</td>\n",
       "      <td>It's failing because the selenium-wire library...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>I am currently trying to scrape data from the ...</td>\n",
       "      <td>You can do this much faster using Requests and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>options.add_argument('--disable-blink-features...</td>\n",
       "      <td>Javascript fingerprinting and context analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>I'm trying to automate away downloading multip...</td>\n",
       "      <td>I was able to get it to work. The selector is:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>I am trying to web scrape the website savevide...</td>\n",
       "      <td>JSOUP is a Static HTML parser. You cannot pars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>I'm using this github code to try to get the p...</td>\n",
       "      <td>In the source is already a similar example (co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     import time from playwright.sync_api import sy...   \n",
       "1     I am trying to scroll the datasheet automatica...   \n",
       "2     I tried to web scraping from this website to g...   \n",
       "3     I would like to extract data from the the tabl...   \n",
       "4     I'm creating a scraper connected to a Telegram...   \n",
       "...                                                 ...   \n",
       "2646  I am currently trying to scrape data from the ...   \n",
       "2647  options.add_argument('--disable-blink-features...   \n",
       "2648  I'm trying to automate away downloading multip...   \n",
       "2649  I am trying to web scrape the website savevide...   \n",
       "2650  I'm using this github code to try to get the p...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Locators check visibility, but you don't care ...  \n",
       "1     Try this:\\ndocument.querySelector(\".showMoreRe...  \n",
       "2     Replace\\nsales = cells[4].text.strip()\\nWith\\n...  \n",
       "3     Instead of using SelectorGadget or element ins...  \n",
       "4     It's failing because the selenium-wire library...  \n",
       "...                                                 ...  \n",
       "2646  You can do this much faster using Requests and...  \n",
       "2647  Javascript fingerprinting and context analysis...  \n",
       "2648  I was able to get it to work. The selector is:...  \n",
       "2649  JSOUP is a Static HTML parser. You cannot pars...  \n",
       "2650  In the source is already a similar example (co...  \n",
       "\n",
       "[2651 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop des lignes vides ou avec moiiins de 10 caractères\n",
    "df1 = df1[df1['question'].str.len() > 10]\n",
    "df1 = df1[df1['answer'].str.len() > 10]\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('stackoverflow2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    return links\n",
    " \n",
    "def get_all_links():\n",
    "    links = []\n",
    "    for n in range(1,1020):\n",
    "        h = get_link('https://stackoverflow.com/questions/tagged/web-scraping?tab=votes&page='+ str(n) +'&pagesize=50')\n",
    "        links.append(h)\n",
    "    return links\n",
    "\n",
    "links1 = get_all_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls2 = get_urls(links1)\n",
    "unique_urls2 = pd.Series(urls2).unique()\n",
    "urls2 = unique_urls2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>I have been trying to display the review ratin...</td>\n",
       "      <td>We can get the relevant information from the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>I have been following FC Pythons tutorial on w...</td>\n",
       "      <td>The range(1,41,2) is used to avoid duplicated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>Playwright is not working as expected when i t...</td>\n",
       "      <td>As Michael said, the purpose of the $ function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>I am trying to scrape the Advances/Declines fr...</td>\n",
       "      <td>This page uses JavaScript to load these inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>I want to extract a table from this website af...</td>\n",
       "      <td>You can use pandas to read_html() and store in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                                                         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "7781  I have been trying to display the review ratin...   \n",
       "7782  I have been following FC Pythons tutorial on w...   \n",
       "7783  Playwright is not working as expected when i t...   \n",
       "7784  I am trying to scrape the Advances/Declines fr...   \n",
       "7785  I want to extract a table from this website af...   \n",
       "\n",
       "                                                 answer  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "7781  We can get the relevant information from the c...  \n",
       "7782  The range(1,41,2) is used to avoid duplicated ...  \n",
       "7783  As Michael said, the purpose of the $ function...  \n",
       "7784  This page uses JavaScript to load these inform...  \n",
       "7785  You can use pandas to read_html() and store in...  \n",
       "\n",
       "[7786 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = HTMLSession()\n",
    "data = []\n",
    "executor = ThreadPoolExecutor(max_workers=11)\n",
    "future2 = executor.submit(scrape_url, urls2)\n",
    "data2 = future2.result()\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I started to use Scrapy for a small project an...</td>\n",
       "      <td>your xpath query is wrong\\nfor entry in sel.xp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have this little website i want to fill in a...</td>\n",
       "      <td>As you might see from the snipped you posted, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm trying to learn how I can use timeout with...</td>\n",
       "      <td>According to the Documentation - Quick Start.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have a website I would like to click a butto...</td>\n",
       "      <td>Basically, you have two options:\\nhigh-level a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is a website I'm scraping that will some...</td>\n",
       "      <td>Follow the EAFP principle:\\nEasier to ask for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>I have been trying to display the review ratin...</td>\n",
       "      <td>We can get the relevant information from the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>I have been following FC Pythons tutorial on w...</td>\n",
       "      <td>The range(1,41,2) is used to avoid duplicated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>Playwright is not working as expected when i t...</td>\n",
       "      <td>As Michael said, the purpose of the $ function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>I am trying to scrape the Advances/Declines fr...</td>\n",
       "      <td>This page uses JavaScript to load these inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>I want to extract a table from this website af...</td>\n",
       "      <td>You can use pandas to read_html() and store in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     I started to use Scrapy for a small project an...   \n",
       "1     I have this little website i want to fill in a...   \n",
       "2     I'm trying to learn how I can use timeout with...   \n",
       "3     I have a website I would like to click a butto...   \n",
       "4     There is a website I'm scraping that will some...   \n",
       "...                                                 ...   \n",
       "6045  I have been trying to display the review ratin...   \n",
       "6046  I have been following FC Pythons tutorial on w...   \n",
       "6047  Playwright is not working as expected when i t...   \n",
       "6048  I am trying to scrape the Advances/Declines fr...   \n",
       "6049  I want to extract a table from this website af...   \n",
       "\n",
       "                                                 answer  \n",
       "0     your xpath query is wrong\\nfor entry in sel.xp...  \n",
       "1     As you might see from the snipped you posted, ...  \n",
       "2     According to the Documentation - Quick Start.\\...  \n",
       "3     Basically, you have two options:\\nhigh-level a...  \n",
       "4     Follow the EAFP principle:\\nEasier to ask for ...  \n",
       "...                                                 ...  \n",
       "6045  We can get the relevant information from the c...  \n",
       "6046  The range(1,41,2) is used to avoid duplicated ...  \n",
       "6047  As Michael said, the purpose of the $ function...  \n",
       "6048  This page uses JavaScript to load these inform...  \n",
       "6049  You can use pandas to read_html() and store in...  \n",
       "\n",
       "[6050 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop des lignes vides ou avec moiiins de 10 caractères\n",
    "df2 = df2[df2['question'].str.len() > 10]\n",
    "df2 = df2[df2['answer'].str.len() > 10]\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('stackoverflow3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
