{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "from mistralai.models.jobs import TrainingParameters\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "client = MistralClient(api_key=api_key)\n",
    "model= 'mistral-small-2402'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", \n",
    "                content=\"Qu'est-ce que le machine learning ?\")\n",
    "]\n",
    "\n",
    "response = client.chat(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "chat_response = response.dict()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le machine learning, ou apprentissage automatique en français, est une branche de l'intelligence artificielle qui permet aux ordinateurs et aux machines d'apprendre à partir de données et d'améliorer leurs performances sur une tâche spécifique sans être explicitement programmés.\\n\\nIl existe plusieurs types de machine learning, notamment l'apprentissage supervisé, l'apprentissage non supervisé et l'apprentissage par renforcement. L'apprentissage supervisé consiste à entraîner un modèle à partir de données étiquetées, c'est-à-dire de données pour lesquelles la réponse correcte est déjà connue. L'apprentissage non supervisé, quant à lui, consiste à entraîner un modèle à partir de données non étiquetées, c'est-à-dire de données pour lesquelles la réponse correcte n'est pas connue. L'apprentissage par renforcement consiste à entraîner un modèle à partir d'une récompense ou d'une pénalité reçue en fonction de ses actions.\\n\\nLe machine learning a de nombreuses applications, notamment dans la reconnaissance d'images, la reconnaissance vocale, la traduction automatique, la prédiction de séries temporelles, la recommandation de produits, la détection de fraudes, etc. Il est utilisé par de nombreuses entreprises pour améliorer leurs produits et services, et il est considéré comme l'une des technologies les plus importantes pour l'avenir de l'informatique et de l'industrie.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('stackoverflow1.csv').dropna()\n",
    "df2 = pd.read_csv('stackoverflow2.csv').dropna()\n",
    "df3 = pd.read_csv('stackoverflow3.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str(_df: pd.DataFrame, _column: str):\n",
    "    _df[_column] = _df[_column].str.replace('\\n', ' ')\n",
    "    _df[_column] = _df[_column].str.replace('\\r', ' ')\n",
    "    _df[_column] = _df[_column].str.replace('\\t', ' ')\n",
    "    _df[_column] = _df[_column].str.lower()\\\n",
    "        .str.replace(r'[^\\w\\s/<>=]', '')\\\n",
    "        .str.replace(r'\\s+', ' ')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(_df: pd.DataFrame):\n",
    "    _df = _df.dropna()\n",
    "    _df.drop_duplicates(inplace=True)\n",
    "    _df.reset_index(inplace=True, drop=True)\n",
    "    _df['answer'] = _df['answer'].str.split('\\nShare').str[0]\n",
    "    _df = replace_str(_df, 'answer')\n",
    "    _df = replace_str(_df, 'question')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_process_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in the DataFrame: 3706313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/qcsfk0590zj_zrqnrs3xwnxr0000gn/T/ipykernel_5035/2006679773.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  token_counts = df.applymap(count_tokens)\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "token_counts = df.applymap(count_tokens)\n",
    "\n",
    "total_token_count = token_counts.sum().sum()\n",
    "\n",
    "print(f'Total number of tokens in the DataFrame: {total_token_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for index, row in df.iterrows():\n",
    "    data_list.append({\n",
    "        \"rôle\": 'user',\n",
    "        \"output\": row['question']\n",
    "    })\n",
    "    data_list.append({\n",
    "        \"rôle\": 'assistant',\n",
    "        \"output\": row['answer']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('stackoverflow.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('stackoverflow.parquet')\n",
    "\n",
    "df_train = df.sample(frac=0.9)\n",
    "df_eval = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path = 'training_file.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file saved at training_file.jsonl\n"
     ]
    }
   ],
   "source": [
    "records = df_train.to_dict(orient='records')\n",
    "\n",
    "with open(jsonl_path, 'w') as file:\n",
    "    for index, row in enumerate(records):\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['question']\n",
    "        }\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": row['answer']\n",
    "        }\n",
    "        jsonl_format = {\"messages\": [user_message, assistant_message]}\n",
    "        file.write(json.dumps(jsonl_format) + '\\n')\n",
    "\n",
    "print(f'JSONL file saved at {jsonl_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path = 'evaluation_file.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file saved at evaluation_file.jsonl\n"
     ]
    }
   ],
   "source": [
    "records = df_eval.to_dict(orient='records')\n",
    "\n",
    "with open(jsonl_path, 'w') as file:\n",
    "    for index, row in enumerate(records):\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['question']\n",
    "        }\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": row['answer']\n",
    "        }\n",
    "        jsonl_format = {\"messages\": [user_message, assistant_message]}\n",
    "        file.write(json.dumps(jsonl_format) + '\\n')\n",
    "\n",
    "print(f'JSONL file saved at {jsonl_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file uploaded\n",
      "Evaluation file uploaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"training_file.jsonl\", \"rb\") as f:\n",
    "    training_data = client.files.create(file=(\"training_file.jsonl\", f)) \n",
    "\n",
    "print(\"Training file uploaded\")\n",
    "\n",
    "with open(\"evaluation_file.jsonl\", \"rb\") as f:\n",
    "    evaluation_data = client.files.create(file=(\"evaluation_file.jsonl\", f)) \n",
    "\n",
    "print(\"Evaluation file uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "MistralAPIException",
     "evalue": "Status: 422. Message: {\"detail\": \"The given validation set is too big. It should not exceed more than 1000000 bytes, but it is 3384199.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMistralAPIException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m created_jobs \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopen-mistral-7b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mevaluation_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrainingParameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m created_jobs\n",
      "File \u001b[0;32m~/Desktop/LeScrapper/.venv/lib/python3.12/site-packages/mistralai/jobs.py:47\u001b[0m, in \u001b[0;36mJobsClient.create\u001b[0;34m(self, model, training_files, validation_files, hyperparameters, suffix, integrations, training_file, validation_file, dry_run)\u001b[0m\n\u001b[1;32m     33\u001b[0m     validation_files \u001b[38;5;241m=\u001b[39m [validation_file]\n\u001b[1;32m     34\u001b[0m single_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m     35\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     json\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdry_run\u001b[39m\u001b[38;5;124m\"\u001b[39m: dry_run},\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msingle_response\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mJobMetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MistralException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo response received\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/LeScrapper/.venv/lib/python3.12/site-packages/mistralai/client.py:142\u001b[0m, in \u001b[0;36mMistralClient._request\u001b[0;34m(self, method, json, path, stream, attempt, data, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    134\u001b[0m             method,\n\u001b[1;32m    135\u001b[0m             url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    140\u001b[0m         )\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MistralConnectionException(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LeScrapper/.venv/lib/python3.12/site-packages/mistralai/client.py:75\u001b[0m, in \u001b[0;36mMistralClient._check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: Response) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response_status_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     json_response: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m json_response:\n",
      "File \u001b[0;32m~/Desktop/LeScrapper/.venv/lib/python3.12/site-packages/mistralai/client.py:60\u001b[0m, in \u001b[0;36mMistralClient._check_response_status_codes\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m     59\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MistralAPIException\u001b[38;5;241m.\u001b[39mfrom_response(\n\u001b[1;32m     61\u001b[0m         response,\n\u001b[1;32m     62\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstream:\n",
      "\u001b[0;31mMistralAPIException\u001b[0m: Status: 422. Message: {\"detail\": \"The given validation set is too big. It should not exceed more than 1000000 bytes, but it is 3384199.\"}"
     ]
    }
   ],
   "source": [
    "created_jobs = client.jobs.create(\n",
    "        model=\"open-mistral-7b\",\n",
    "        training_files=[training_data.id],\n",
    "        validation_files=[evaluation_data.id],\n",
    "        hyperparameters=TrainingParameters(\n",
    "        training_steps=10,\n",
    "        learning_rate=0.0001,\n",
    "        )\n",
    ")\n",
    "created_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_jobs = client.jobs.retrieve(created_jobs.id)\n",
    "print(retrieved_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = client.chat(\n",
    "    model=retrieved_jobs.fine_tuned_model,\n",
    "    messages=[ChatMessage(role='user', content=\"Qu'est-ce que le scrapping ?\")]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
