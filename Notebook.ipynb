{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "from mistralai.models.jobs import TrainingParameters\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "client = MistralClient(api_key=api_key)\n",
    "model= 'mistral-small-latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Mistral API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", \n",
    "                content=\"Qu'est-ce que le machine learning ?\")\n",
    "]\n",
    "\n",
    "response = client.chat(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "chat_response = response.dict()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le machine learning, ou apprentissage automatique en français, est une branche de l'intelligence artificielle qui permet aux ordinateurs et aux machines d'apprendre à partir de données et d'améliorer leurs performances sur une tâche spécifique sans être explicitement programmés.\\n\\nIl existe plusieurs types de machine learning, notamment l'apprentissage supervisé, l'apprentissage non supervisé et l'apprentissage par renforcement. L'apprentissage supervisé consiste à entraîner un modèle à partir de données étiquetées, c'est-à-dire de données pour lesquelles la réponse correcte est déjà connue. L'apprentissage non supervisé, quant à lui, consiste à entraîner un modèle à partir de données non étiquetées, c'est-à-dire de données pour lesquelles la réponse correcte n'est pas connue. L'apprentissage par renforcement consiste à entraîner un modèle à partir d'une récompense ou d'une pénalité reçue en fonction de ses actions.\\n\\nLe machine learning a de nombreuses applications, notamment dans la reconnaissance d'images, la reconnaissance vocale, la traduction automatique, la prédiction de séries temporelles, la recommandation de produits, la détection de fraudes, etc. Il est utilisé par de nombreuses entreprises pour améliorer leurs produits et services, et il est considéré comme l'une des technologies les plus importantes pour l'avenir de l'informatique et de l'industrie.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of the scrapped data into a jsonl file for the Mistral API Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('stackoverflow1.csv').dropna()\n",
    "df2 = pd.read_csv('stackoverflow2.csv').dropna()\n",
    "df3 = pd.read_csv('stackoverflow3.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_str(_df: pd.DataFrame, _column: str):\n",
    "    _df[_column] = _df[_column].str.replace('\\n', ' ')\n",
    "    _df[_column] = _df[_column].str.replace('\\r', ' ')\n",
    "    _df[_column] = _df[_column].str.replace('\\t', ' ')\n",
    "    _df[_column] = _df[_column].str.lower()\\\n",
    "        .str.replace(r'[^\\w\\s/<>=]', '')\\\n",
    "        .str.replace(r'\\s+', ' ')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(_df: pd.DataFrame):\n",
    "    _df = _df.dropna()\n",
    "    _df.drop_duplicates(inplace=True)\n",
    "    _df.reset_index(inplace=True, drop=True)\n",
    "    _df['answer'] = _df['answer'].str.split('\\nShare').str[0]\n",
    "    _df = replace_str(_df, 'answer')\n",
    "    _df = replace_str(_df, 'question')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_process_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in the DataFrame: 3706313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/qcsfk0590zj_zrqnrs3xwnxr0000gn/T/ipykernel_30125/2006679773.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  token_counts = df.applymap(count_tokens)\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "token_counts = df.applymap(count_tokens)\n",
    "\n",
    "total_token_count = token_counts.sum().sum()\n",
    "\n",
    "print(f'Total number of tokens in the DataFrame: {total_token_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for index, row in df.iterrows():\n",
    "    data_list.append({\n",
    "        \"rôle\": 'user',\n",
    "        \"output\": row['question']\n",
    "    })\n",
    "    data_list.append({\n",
    "        \"rôle\": 'assistant',\n",
    "        \"output\": row['answer']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('stackoverflow.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have parquet file, run the first cell and here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('stackoverflow.parquet')\n",
    "\n",
    "df_train = df.sample(frac=0.9)\n",
    "df_eval = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path = 'training_file.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file saved at training_file.jsonl\n"
     ]
    }
   ],
   "source": [
    "records = df_train.to_dict(orient='records')\n",
    "\n",
    "with open(jsonl_path, 'w') as file:\n",
    "    for index, row in enumerate(records):\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['question']\n",
    "        }\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": row['answer']\n",
    "        }\n",
    "        jsonl_format = {\"messages\": [user_message, assistant_message]}\n",
    "        file.write(json.dumps(jsonl_format) + '\\n')\n",
    "\n",
    "print(f'JSONL file saved at {jsonl_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_path = 'evaluation_file.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL file saved at evaluation_file.jsonl\n"
     ]
    }
   ],
   "source": [
    "records = df_eval.to_dict(orient='records')\n",
    "\n",
    "with open(jsonl_path, 'w') as file:\n",
    "    for index, row in enumerate(records):\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row['question']\n",
    "        }\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": row['answer']\n",
    "        }\n",
    "        jsonl_format = {\"messages\": [user_message, assistant_message]}\n",
    "        file.write(json.dumps(jsonl_format) + '\\n')\n",
    "\n",
    "print(f'JSONL file saved at {jsonl_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Mistral API of the training data and evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file uploaded\n",
      "Evaluation file uploaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"training_file.jsonl\", \"rb\") as f:\n",
    "    training_data = client.files.create(file=(\"training_file.jsonl\", f)) \n",
    "\n",
    "print(\"Training file uploaded\")\n",
    "\n",
    "with open(\"evaluation_file.jsonl\", \"rb\") as f:\n",
    "    evaluation_data = client.files.create(file=(\"evaluation_file.jsonl\", f)) \n",
    "\n",
    "print(\"Evaluation file uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job(id='11adbf10-bc96-4f91-bd95-b7ff41f2b83c', hyperparameters=TrainingParameters(training_steps=50, learning_rate=0.0001), fine_tuned_model=None, model='mistral-small-latest', status='QUEUED', job_type='FT', created_at=1719587199, modified_at=1719587199, training_files=['a1818d5d-1aa9-47ec-af49-4de158e3c7d8'], validation_files=['f73524a6-0533-4f91-8a13-b3bef2a83db2'], object='job', integrations=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_jobs = client.jobs.create(\n",
    "        model=model,\n",
    "        training_files=[training_data.id],\n",
    "        validation_files=[evaluation_data.id],\n",
    "        hyperparameters=TrainingParameters(\n",
    "        training_steps=50,\n",
    "        learning_rate=0.0001,\n",
    "        )\n",
    ")\n",
    "created_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='11adbf10-bc96-4f91-bd95-b7ff41f2b83c' hyperparameters=TrainingParameters(training_steps=50, learning_rate=0.0001) fine_tuned_model=None model='mistral-small-latest' status='RUNNING' job_type='FT' created_at=1719587199 modified_at=1719587199 training_files=['a1818d5d-1aa9-47ec-af49-4de158e3c7d8'] validation_files=['f73524a6-0533-4f91-8a13-b3bef2a83db2'] object='job' integrations=[] events=[Event(name='status-updated', data={'status': 'RUNNING'}, created_at=1719587199), Event(name='status-updated', data={'status': 'QUEUED'}, created_at=1719587199)] checkpoints=[] estimated_start_time=None\n"
     ]
    }
   ],
   "source": [
    "retrieved_jobs = client.jobs.retrieve(created_jobs.id)\n",
    "\n",
    "print(retrieved_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le Scrapper model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetailedJob(id='11adbf10-bc96-4f91-bd95-b7ff41f2b83c', hyperparameters=TrainingParameters(training_steps=50, learning_rate=0.0001), fine_tuned_model=None, model='mistral-small-latest', status='RUNNING', job_type='FT', created_at=1719587199, modified_at=1719587199, training_files=['a1818d5d-1aa9-47ec-af49-4de158e3c7d8'], validation_files=['f73524a6-0533-4f91-8a13-b3bef2a83db2'], object='job', integrations=[], events=[Event(name='status-updated', data={'status': 'RUNNING'}, created_at=1719587199), Event(name='status-updated', data={'status': 'QUEUED'}, created_at=1719587199)], checkpoints=[], estimated_start_time=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = client.chat(\n",
    "    model=retrieved_jobs.model,\n",
    "    messages=[ChatMessage(role='user', content=\"Qu'est-ce que le scrapping ?\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le scrapping, également connu sous le nom de web scrapping ou data scraping, est une technique utilisée pour extraire des données de sites web. Il s'agit d'un processus automatisé qui permet de collecter et d'analyser des informations en ligne. Les robots d'exploration de données, ou scrapers, sont utilisés pour naviguer sur les sites web et extraire les données spécifiques nécessaires, telles que des prix, des avis, des coordonnées, etc. Le scrapping peut être utile pour des recherches, des analyses de marché, la veille concurrentielle, ou encore pour alimenter une base de données. Cependant, il est important de noter que le scrapping doit être effectué dans le respect des conditions d'utilisation des sites web et des lois sur la protection des données.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.dict()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetailedJob(id='11adbf10-bc96-4f91-bd95-b7ff41f2b83c', hyperparameters=TrainingParameters(training_steps=50, learning_rate=0.0001), fine_tuned_model=None, model='mistral-small-latest', status='RUNNING', job_type='FT', created_at=1719587199, modified_at=1719587199, training_files=['a1818d5d-1aa9-47ec-af49-4de158e3c7d8'], validation_files=['f73524a6-0533-4f91-8a13-b3bef2a83db2'], object='job', integrations=[], events=[Event(name='status-updated', data={'status': 'RUNNING'}, created_at=1719587199), Event(name='status-updated', data={'status': 'QUEUED'}, created_at=1719587199)], checkpoints=[], estimated_start_time=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
